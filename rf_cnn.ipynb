{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1KTvMheDye7Wv-RkRj9g4mMGxdGy5kCSk",
      "authorship_tag": "ABX9TyNX/sC+WKuqIeEelLA3zpZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gowri0109/-Image-Processing-for-Brain-Tumor-Classification-and-detection/blob/new/rf_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gowri0109/-Image-Processing-for-Brain-Tumor-Classification-and-detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oewb7x3SO7-Z",
        "outputId": "af110f4e-8318-4357-cb4f-b89e7d8b3ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '-Image-Processing-for-Brain-Tumor-Classification-and-detection'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 134 (delta 75), reused 80 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (134/134), 983.67 KiB | 8.27 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test run\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Assuming your test data is stored in a directory named \"test_data_folder\"\n",
        "test_data_folder = \"/content/drive/MyDrive/features/test_set\"\n",
        "\n",
        "# List all subdirectories in the test data folder\n",
        "subdirectories = os.listdir(test_data_folder)\n",
        "\n",
        "# Load images and labels for the test set\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in subdirectories:\n",
        "    subdirectory_path = os.path.join(test_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_test.append(resized_image)  # Add the image to the test feature matrix\n",
        "            y_test.append(subdirectory)  # Use the subdirectory name as the label for test data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Random Forest Classifier\n",
        "# Flatten the images\n",
        "X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_clf.fit(X_test_flattened, y_test)\n",
        "\n",
        "# Perform prediction\n",
        "y_test_pred_rf = rf_clf.predict(X_test_flattened)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
        "print(\"Random Forest Test Accuracy: {:.2f}%\".format(test_accuracy_rf * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcsI-nI9GBw8",
        "outputId": "3cd89188-14e9-4910-b771-14ca78b18731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training and validation\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your training data is stored in a directory named \"train_data_folder\"\n",
        "train_data_folder = \"/content/drive/MyDrive/features/training_set\"\n",
        "\n",
        "# Assuming your validation data is stored in a directory named \"validation_data_folder\"\n",
        "validation_data_folder = \"/content/drive/MyDrive/features/validation_set\"\n",
        "\n",
        "# List all subdirectories in the training data folder\n",
        "train_subdirectories = os.listdir(train_data_folder)\n",
        "\n",
        "# List all subdirectories in the validation data folder\n",
        "validation_subdirectories = os.listdir(validation_data_folder)\n",
        "\n",
        "# Load images and labels for the training set\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Load images and labels for the validation set\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in train_subdirectories:\n",
        "    subdirectory_path = os.path.join(train_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_train.append(resized_image.flatten())  # Add the flattened image to the training feature matrix\n",
        "            y_train.append(subdirectory)  # Use the subdirectory name as the label for training data\n",
        "\n",
        "for subdirectory in validation_subdirectories:\n",
        "    subdirectory_path = os.path.join(validation_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_val.append(resized_image.flatten())  # Add the flattened image to the validation feature matrix\n",
        "            y_val.append(subdirectory)  # Use the subdirectory name as the label for validation data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "# Preprocess the images and labels as per your requirements\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Perform prediction on the validation set\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "print(\"Random Forest Validation Accuracy: {:.2f}%\".format(val_accuracy_rf * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5SLTXWtORTy",
        "outputId": "0962b72c-6cde-4896-aaa3-5998c512c649"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Validation Accuracy: 89.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming your test data is stored in a directory named \"test_data_folder\"\n",
        "test_data_folder = \"/content/drive/MyDrive/features/test_set\"\n",
        "\n",
        "# List all subdirectories in the test data folder\n",
        "subdirectories = os.listdir(test_data_folder)\n",
        "\n",
        "# Load images and labels for the test set\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in subdirectories:\n",
        "    subdirectory_path = os.path.join(test_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_test.append(resized_image)  # Add the image to the test feature matrix\n",
        "            y_test.append(subdirectory)  # Use the subdirectory name as the label for test data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Preprocess the images (e.g., normalize, convert to grayscale, etc.) as per your requirements\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "\n",
        "# Convert numeric labels to one-hot encoded vectors\n",
        "y_test_one_hot = to_categorical(y_test_encoded)\n",
        "\n",
        "# Create a CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_test.shape[1:]))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(y_test_one_hot.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Perform prediction\n",
        "y_test_pred_cnn = cnn_model.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_test_pred_cnn_labels = np.argmax(y_test_pred_cnn, axis=1)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "test_accuracy_cnn = accuracy_score(y_test_encoded, y_test_pred_cnn_labels)\n",
        "print(\"CNN Test Accuracy: {:.2f}%\".format(test_accuracy_cnn * 100))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACulwElVD38o",
        "outputId": "8b69f73f-e846-422d-e8f6-6f2f82fe5398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134/134 [==============================] - 7s 2ms/step\n",
            "CNN Test Accuracy: 28.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your training data is stored in a directory named \"train_data_folder\"\n",
        "train_data_folder = \"/content/drive/MyDrive/features/training_set\"\n",
        "\n",
        "# Assuming your validation data is stored in a directory named \"validation_data_folder\"\n",
        "validation_data_folder = \"/content/drive/MyDrive/features/validation_set\"\n",
        "\n",
        "# List all subdirectories in the training data folder\n",
        "train_subdirectories = os.listdir(train_data_folder)\n",
        "\n",
        "# List all subdirectories in the validation data folder\n",
        "validation_subdirectories = os.listdir(validation_data_folder)\n",
        "\n",
        "# Load images and labels for the training set\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Load images and labels for the validation set\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in train_subdirectories:\n",
        "    subdirectory_path = os.path.join(train_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_train.append(resized_image)  # Add the image to the training feature matrix\n",
        "            y_train.append(subdirectory)  # Use the subdirectory name as the label for training data\n",
        "\n",
        "for subdirectory in validation_subdirectories:\n",
        "    subdirectory_path = os.path.join(validation_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_val.append(resized_image)  # Add the image to the validation feature matrix\n",
        "            y_val.append(subdirectory)  # Use the subdirectory name as the label for validation data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "# Preprocess the images (e.g., normalize, convert to grayscale, etc.) as per your requirements\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert numeric labels to one-hot encoded vectors\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n",
        "y_val_one_hot = to_categorical(y_val_encoded, num_classes)\n",
        "\n",
        "# Create a CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32, validation_data=(X_val, y_val_one_hot))\n",
        "\n",
        "# Perform prediction on the validation set\n",
        "y_val_pred_cnn = cnn_model.predict(X_val)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_val_pred_cnn_labels = np.argmax(y_val_pred_cnn, axis=1)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_cnn = accuracy_score(y_val_encoded, y_val_pred_cnn_labels)\n",
        "print(\"CNN Validation Accuracy: {:.2f}%\".format(validation_accuracy_cnn * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlJZUFM4VqOp",
        "outputId": "95eca729-e407-4e2b-faee-62008025e54e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "624/624 [==============================] - 14s 6ms/step - loss: 19.3533 - accuracy: 0.3239 - val_loss: 1.3184 - val_accuracy: 0.3183\n",
            "Epoch 2/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.3129 - accuracy: 0.3189 - val_loss: 1.2890 - val_accuracy: 0.3213\n",
            "Epoch 3/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2799 - accuracy: 0.3236 - val_loss: 1.3020 - val_accuracy: 0.3194\n",
            "Epoch 4/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2802 - accuracy: 0.3241 - val_loss: 1.2952 - val_accuracy: 0.3192\n",
            "Epoch 5/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2935 - accuracy: 0.3195 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "Epoch 6/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2935 - accuracy: 0.3195 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "Epoch 7/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2935 - accuracy: 0.3195 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "Epoch 8/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2935 - accuracy: 0.3194 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "Epoch 9/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 1.2935 - accuracy: 0.3195 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "Epoch 10/10\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 1.2935 - accuracy: 0.3195 - val_loss: 1.2951 - val_accuracy: 0.3192\n",
            "134/134 [==============================] - 0s 2ms/step\n",
            "CNN Validation Accuracy: 31.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your training data is stored in a directory named \"train_data_folder\"\n",
        "train_data_folder = \"/content/drive/MyDrive/features/training_set\"\n",
        "\n",
        "# Assuming your validation data is stored in a directory named \"validation_data_folder\"\n",
        "validation_data_folder = \"/content/drive/MyDrive/features/validation_set\"\n",
        "\n",
        "# List all subdirectories in the training data folder\n",
        "train_subdirectories = os.listdir(train_data_folder)\n",
        "\n",
        "# List all subdirectories in the validation data folder\n",
        "validation_subdirectories = os.listdir(validation_data_folder)\n",
        "\n",
        "# Load images and labels for the training set\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Load images and labels for the validation set\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in train_subdirectories:\n",
        "    subdirectory_path = os.path.join(train_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_train.append(resized_image)  # Add the image to the training feature matrix\n",
        "            y_train.append(subdirectory)  # Use the subdirectory name as the label for training data\n",
        "\n",
        "for subdirectory in validation_subdirectories:\n",
        "    subdirectory_path = os.path.join(validation_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_val.append(resized_image)  # Add the image to the validation feature matrix\n",
        "            y_val.append(subdirectory)  # Use the subdirectory name as the label for validation data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "# Preprocess the images (e.g., normalize, convert to grayscale, etc.) as per your requirements\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert numeric labels to one-hot encoded vectors\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n",
        "y_val_one_hot = to_categorical(y_val_encoded, num_classes)\n",
        "\n",
        "# Create a CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train, y_train_one_hot, epochs=50, batch_size=32, validation_data=(X_val, y_val_one_hot))\n",
        "\n",
        "# Perform prediction on the validation set\n",
        "y_val_pred_cnn = cnn_model.predict(X_val)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_val_pred_cnn_labels = np.argmax(y_val_pred_cnn, axis=1)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_cnn = accuracy_score(y_val_encoded, y_val_pred_cnn_labels)\n",
        "print(\"CNN Validation Accuracy: {:.2f}%\".format(validation_accuracy_cnn * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhrsmVaMV1eO",
        "outputId": "301ffbfb-ec90-4113-f1e3-4aca29c4c461"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "624/624 [==============================] - 5s 6ms/step - loss: 14.9651 - accuracy: 0.6330 - val_loss: 1.1280 - val_accuracy: 0.7187\n",
            "Epoch 2/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.7803 - accuracy: 0.7690 - val_loss: 0.9030 - val_accuracy: 0.7592\n",
            "Epoch 3/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.4971 - accuracy: 0.8297 - val_loss: 0.7334 - val_accuracy: 0.8179\n",
            "Epoch 4/50\n",
            "624/624 [==============================] - 4s 7ms/step - loss: 0.3711 - accuracy: 0.8664 - val_loss: 0.7060 - val_accuracy: 0.8242\n",
            "Epoch 5/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.3095 - accuracy: 0.8916 - val_loss: 0.7731 - val_accuracy: 0.8107\n",
            "Epoch 6/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2911 - accuracy: 0.8954 - val_loss: 0.7035 - val_accuracy: 0.8416\n",
            "Epoch 7/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9190 - val_loss: 0.7889 - val_accuracy: 0.8374\n",
            "Epoch 8/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.1885 - accuracy: 0.9283 - val_loss: 0.6881 - val_accuracy: 0.8626\n",
            "Epoch 9/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.9224 - val_loss: 0.7724 - val_accuracy: 0.8395\n",
            "Epoch 10/50\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.1969 - accuracy: 0.9274 - val_loss: 0.7350 - val_accuracy: 0.8514\n",
            "Epoch 11/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9307 - val_loss: 0.8387 - val_accuracy: 0.8411\n",
            "Epoch 12/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.1856 - accuracy: 0.9356 - val_loss: 0.8186 - val_accuracy: 0.8418\n",
            "Epoch 13/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1759 - accuracy: 0.9379 - val_loss: 0.8999 - val_accuracy: 0.8409\n",
            "Epoch 14/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1458 - accuracy: 0.9480 - val_loss: 0.7270 - val_accuracy: 0.8638\n",
            "Epoch 15/50\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.1298 - accuracy: 0.9512 - val_loss: 0.7072 - val_accuracy: 0.8666\n",
            "Epoch 16/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1395 - accuracy: 0.9478 - val_loss: 0.7707 - val_accuracy: 0.8636\n",
            "Epoch 17/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9592 - val_loss: 0.6987 - val_accuracy: 0.8715\n",
            "Epoch 18/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9534 - val_loss: 0.8401 - val_accuracy: 0.8551\n",
            "Epoch 19/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9560 - val_loss: 0.9272 - val_accuracy: 0.8535\n",
            "Epoch 20/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9484 - val_loss: 1.0590 - val_accuracy: 0.7950\n",
            "Epoch 21/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.1214 - accuracy: 0.9599 - val_loss: 0.8502 - val_accuracy: 0.8711\n",
            "Epoch 22/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0870 - accuracy: 0.9701 - val_loss: 1.1245 - val_accuracy: 0.8069\n",
            "Epoch 23/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0934 - accuracy: 0.9677 - val_loss: 0.8289 - val_accuracy: 0.8668\n",
            "Epoch 24/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0686 - accuracy: 0.9749 - val_loss: 0.9387 - val_accuracy: 0.8645\n",
            "Epoch 25/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 1.0776 - val_accuracy: 0.8411\n",
            "Epoch 26/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.9600 - val_loss: 0.9276 - val_accuracy: 0.8711\n",
            "Epoch 27/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 0.9967 - val_accuracy: 0.8598\n",
            "Epoch 28/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0666 - accuracy: 0.9764 - val_loss: 0.9475 - val_accuracy: 0.8682\n",
            "Epoch 29/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0963 - accuracy: 0.9661 - val_loss: 1.0689 - val_accuracy: 0.8671\n",
            "Epoch 30/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 1.0662 - val_accuracy: 0.8636\n",
            "Epoch 31/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0547 - accuracy: 0.9796 - val_loss: 0.9299 - val_accuracy: 0.8771\n",
            "Epoch 32/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.9163 - val_accuracy: 0.8748\n",
            "Epoch 33/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0543 - accuracy: 0.9804 - val_loss: 1.1328 - val_accuracy: 0.8746\n",
            "Epoch 34/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 1.0845 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0909 - accuracy: 0.9730 - val_loss: 0.9852 - val_accuracy: 0.8593\n",
            "Epoch 36/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0743 - accuracy: 0.9781 - val_loss: 1.0727 - val_accuracy: 0.8806\n",
            "Epoch 37/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0655 - accuracy: 0.9808 - val_loss: 1.2121 - val_accuracy: 0.8734\n",
            "Epoch 38/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 1.2216 - val_accuracy: 0.8802\n",
            "Epoch 39/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 1.2608 - val_accuracy: 0.8703\n",
            "Epoch 40/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0636 - accuracy: 0.9800 - val_loss: 1.2076 - val_accuracy: 0.8537\n",
            "Epoch 41/50\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 1.0218 - val_accuracy: 0.8783\n",
            "Epoch 42/50\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0537 - accuracy: 0.9834 - val_loss: 1.2595 - val_accuracy: 0.8762\n",
            "Epoch 43/50\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 1.3341 - val_accuracy: 0.8713\n",
            "Epoch 44/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 1.2504 - val_accuracy: 0.8734\n",
            "Epoch 45/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 1.1995 - val_accuracy: 0.8739\n",
            "Epoch 46/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0640 - accuracy: 0.9828 - val_loss: 1.4984 - val_accuracy: 0.8577\n",
            "Epoch 47/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0852 - accuracy: 0.9773 - val_loss: 1.1795 - val_accuracy: 0.8734\n",
            "Epoch 48/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 1.3952 - val_accuracy: 0.8853\n",
            "Epoch 49/50\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 1.3275 - val_accuracy: 0.8701\n",
            "Epoch 50/50\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 1.3306 - val_accuracy: 0.8795\n",
            "134/134 [==============================] - 0s 2ms/step\n",
            "CNN Validation Accuracy: 87.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8Fwrf0CXdD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your training data is stored in a directory named \"train_data_folder\"\n",
        "train_data_folder = \"/content/drive/MyDrive/features/training_set\"\n",
        "\n",
        "# Assuming your validation data is stored in a directory named \"validation_data_folder\"\n",
        "validation_data_folder = \"/content/drive/MyDrive/features/validation_set\"\n",
        "\n",
        "# List all subdirectories in the training data folder\n",
        "train_subdirectories = os.listdir(train_data_folder)\n",
        "\n",
        "# List all subdirectories in the validation data folder\n",
        "validation_subdirectories = os.listdir(validation_data_folder)\n",
        "\n",
        "# Load images and labels for the training set\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Load images and labels for the validation set\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "# Define the fixed size for resizing the images\n",
        "image_size = (64, 64)  # Adjust the size as per your requirements\n",
        "\n",
        "for subdirectory in train_subdirectories:\n",
        "    subdirectory_path = os.path.join(train_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_train.append(resized_image)  # Add the image to the training feature matrix\n",
        "            y_train.append(subdirectory)  # Use the subdirectory name as the label for training data\n",
        "\n",
        "for subdirectory in validation_subdirectories:\n",
        "    subdirectory_path = os.path.join(validation_data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        image_files = os.listdir(subdirectory_path)\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subdirectory_path, image_file)\n",
        "            image = cv2.imread(image_path)  # Load image using OpenCV or any other library\n",
        "            resized_image = cv2.resize(image, image_size)  # Resize the image to a fixed size\n",
        "            X_val.append(resized_image)  # Add the image to the validation feature matrix\n",
        "            y_val.append(subdirectory)  # Use the subdirectory name as the label for validation data\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "# Preprocess the images (e.g., normalize, convert to grayscale, etc.) as per your requirements\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert numeric labels to one-hot encoded vectors\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n",
        "y_val_one_hot = to_categorical(y_val_encoded, num_classes)\n",
        "\n",
        "# Create a CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train, y_train_one_hot, epochs=100, batch_size=32, validation_data=(X_val, y_val_one_hot))\n",
        "\n",
        "# Perform prediction on the validation set\n",
        "y_val_pred_cnn = cnn_model.predict(X_val)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_val_pred_cnn_labels = np.argmax(y_val_pred_cnn, axis=1)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_cnn = accuracy_score(y_val_encoded, y_val_pred_cnn_labels)\n",
        "print(\"CNN Validation Accuracy: {:.2f}%\".format(validation_accuracy_cnn * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c893fc3e-0430-4fa7-a09a-d4f8038834e7",
        "id": "K8M4AE_bY5Wk"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "624/624 [==============================] - 4s 5ms/step - loss: 8.6103 - accuracy: 0.6353 - val_loss: 0.8502 - val_accuracy: 0.7107\n",
            "Epoch 2/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.6156 - accuracy: 0.7789 - val_loss: 0.6512 - val_accuracy: 0.7763\n",
            "Epoch 3/100\n",
            "624/624 [==============================] - 5s 7ms/step - loss: 0.4225 - accuracy: 0.8406 - val_loss: 0.5542 - val_accuracy: 0.8240\n",
            "Epoch 4/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.3208 - accuracy: 0.8821 - val_loss: 0.5777 - val_accuracy: 0.8289\n",
            "Epoch 5/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2628 - accuracy: 0.9037 - val_loss: 0.6096 - val_accuracy: 0.8331\n",
            "Epoch 6/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.9161 - val_loss: 0.6035 - val_accuracy: 0.8446\n",
            "Epoch 7/100\n",
            "624/624 [==============================] - 3s 6ms/step - loss: 0.2344 - accuracy: 0.9185 - val_loss: 0.7548 - val_accuracy: 0.8287\n",
            "Epoch 8/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9275 - val_loss: 0.7624 - val_accuracy: 0.8409\n",
            "Epoch 9/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1816 - accuracy: 0.9384 - val_loss: 0.6457 - val_accuracy: 0.8631\n",
            "Epoch 10/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9436 - val_loss: 0.7209 - val_accuracy: 0.8397\n",
            "Epoch 11/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9450 - val_loss: 0.7186 - val_accuracy: 0.8743\n",
            "Epoch 12/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9549 - val_loss: 0.7127 - val_accuracy: 0.8474\n",
            "Epoch 13/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1351 - accuracy: 0.9520 - val_loss: 0.7600 - val_accuracy: 0.8486\n",
            "Epoch 14/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.1615 - accuracy: 0.9465 - val_loss: 0.9972 - val_accuracy: 0.8554\n",
            "Epoch 15/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9597 - val_loss: 0.7837 - val_accuracy: 0.8725\n",
            "Epoch 16/100\n",
            "624/624 [==============================] - 3s 6ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.8348 - val_accuracy: 0.8598\n",
            "Epoch 17/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9733 - val_loss: 0.9267 - val_accuracy: 0.8617\n",
            "Epoch 18/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9671 - val_loss: 0.8947 - val_accuracy: 0.8657\n",
            "Epoch 19/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 0.8582 - val_accuracy: 0.8781\n",
            "Epoch 20/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0966 - accuracy: 0.9686 - val_loss: 0.8467 - val_accuracy: 0.8703\n",
            "Epoch 21/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0691 - accuracy: 0.9764 - val_loss: 1.1192 - val_accuracy: 0.8610\n",
            "Epoch 22/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0932 - accuracy: 0.9735 - val_loss: 1.3755 - val_accuracy: 0.8303\n",
            "Epoch 23/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 1.0973 - val_accuracy: 0.8675\n",
            "Epoch 24/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 1.0894 - val_accuracy: 0.8682\n",
            "Epoch 25/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9775 - val_loss: 1.0727 - val_accuracy: 0.8725\n",
            "Epoch 26/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 1.0373 - val_accuracy: 0.8802\n",
            "Epoch 27/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0552 - accuracy: 0.9818 - val_loss: 1.1547 - val_accuracy: 0.8774\n",
            "Epoch 28/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 1.2132 - val_accuracy: 0.8741\n",
            "Epoch 29/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 1.3830 - val_accuracy: 0.8334\n",
            "Epoch 30/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0689 - accuracy: 0.9802 - val_loss: 1.3021 - val_accuracy: 0.8711\n",
            "Epoch 31/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 1.1998 - val_accuracy: 0.8799\n",
            "Epoch 32/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 1.3789 - val_accuracy: 0.8650\n",
            "Epoch 33/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 1.3071 - val_accuracy: 0.8589\n",
            "Epoch 34/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 1.3881 - val_accuracy: 0.8760\n",
            "Epoch 35/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 1.3944 - val_accuracy: 0.8804\n",
            "Epoch 36/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 1.5756 - val_accuracy: 0.8493\n",
            "Epoch 37/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0692 - accuracy: 0.9797 - val_loss: 1.4422 - val_accuracy: 0.8673\n",
            "Epoch 38/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0271 - accuracy: 0.9907 - val_loss: 1.7204 - val_accuracy: 0.8647\n",
            "Epoch 39/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0573 - accuracy: 0.9825 - val_loss: 1.4790 - val_accuracy: 0.8783\n",
            "Epoch 40/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0716 - accuracy: 0.9823 - val_loss: 1.5460 - val_accuracy: 0.8692\n",
            "Epoch 41/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0691 - accuracy: 0.9831 - val_loss: 1.4811 - val_accuracy: 0.8385\n",
            "Epoch 42/100\n",
            "624/624 [==============================] - 3s 6ms/step - loss: 0.0460 - accuracy: 0.9874 - val_loss: 1.5745 - val_accuracy: 0.8837\n",
            "Epoch 43/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0564 - accuracy: 0.9884 - val_loss: 1.6353 - val_accuracy: 0.8828\n",
            "Epoch 44/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 1.9533 - val_accuracy: 0.8694\n",
            "Epoch 45/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 1.5460 - val_accuracy: 0.8809\n",
            "Epoch 46/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0516 - accuracy: 0.9874 - val_loss: 1.5380 - val_accuracy: 0.8785\n",
            "Epoch 47/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.7562 - val_accuracy: 0.8830\n",
            "Epoch 48/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.6930 - val_accuracy: 0.8748\n",
            "Epoch 49/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 1.7082 - val_accuracy: 0.8762\n",
            "Epoch 50/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 1.7938 - val_accuracy: 0.8647\n",
            "Epoch 51/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 1.7556 - val_accuracy: 0.8767\n",
            "Epoch 52/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 1.6089 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 1.7671 - val_accuracy: 0.8811\n",
            "Epoch 54/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 1.7607 - val_accuracy: 0.8769\n",
            "Epoch 55/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0510 - accuracy: 0.9867 - val_loss: 1.7709 - val_accuracy: 0.8687\n",
            "Epoch 56/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0399 - accuracy: 0.9891 - val_loss: 1.9115 - val_accuracy: 0.8774\n",
            "Epoch 57/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 1.9918 - val_accuracy: 0.8778\n",
            "Epoch 58/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 1.7590 - val_accuracy: 0.8748\n",
            "Epoch 59/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0401 - accuracy: 0.9907 - val_loss: 2.3620 - val_accuracy: 0.8708\n",
            "Epoch 60/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0424 - accuracy: 0.9899 - val_loss: 2.0794 - val_accuracy: 0.8666\n",
            "Epoch 61/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 1.8844 - val_accuracy: 0.8832\n",
            "Epoch 62/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 1.9906 - val_accuracy: 0.8762\n",
            "Epoch 63/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0462 - accuracy: 0.9882 - val_loss: 1.8569 - val_accuracy: 0.8818\n",
            "Epoch 64/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0675 - accuracy: 0.9855 - val_loss: 1.6308 - val_accuracy: 0.8828\n",
            "Epoch 65/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 2.0362 - val_accuracy: 0.8591\n",
            "Epoch 66/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 1.8415 - val_accuracy: 0.8842\n",
            "Epoch 67/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 2.3608 - val_accuracy: 0.8671\n",
            "Epoch 68/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 2.3903 - val_accuracy: 0.8748\n",
            "Epoch 69/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0678 - accuracy: 0.9844 - val_loss: 2.0411 - val_accuracy: 0.8832\n",
            "Epoch 70/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 1.9837 - val_accuracy: 0.8750\n",
            "Epoch 71/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.9685 - val_accuracy: 0.8874\n",
            "Epoch 72/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 2.0861 - val_accuracy: 0.8860\n",
            "Epoch 73/100\n",
            "624/624 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 2.0919 - val_accuracy: 0.8891\n",
            "Epoch 74/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0469 - accuracy: 0.9890 - val_loss: 1.8424 - val_accuracy: 0.8577\n",
            "Epoch 75/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 1.8399 - val_accuracy: 0.8806\n",
            "Epoch 76/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 1.7962 - val_accuracy: 0.8844\n",
            "Epoch 77/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0479 - accuracy: 0.9906 - val_loss: 2.0706 - val_accuracy: 0.8711\n",
            "Epoch 78/100\n",
            "624/624 [==============================] - 3s 6ms/step - loss: 0.0757 - accuracy: 0.9879 - val_loss: 2.2097 - val_accuracy: 0.8771\n",
            "Epoch 79/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 2.2540 - val_accuracy: 0.8830\n",
            "Epoch 80/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 2.3254 - val_accuracy: 0.8757\n",
            "Epoch 81/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 2.4150 - val_accuracy: 0.8678\n",
            "Epoch 82/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 2.2212 - val_accuracy: 0.8734\n",
            "Epoch 83/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 2.7516 - val_accuracy: 0.8598\n",
            "Epoch 84/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9922 - val_loss: 2.1930 - val_accuracy: 0.8891\n",
            "Epoch 85/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 2.3110 - val_accuracy: 0.8832\n",
            "Epoch 86/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0322 - accuracy: 0.9914 - val_loss: 2.7080 - val_accuracy: 0.8743\n",
            "Epoch 87/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0406 - accuracy: 0.9907 - val_loss: 2.4536 - val_accuracy: 0.8725\n",
            "Epoch 88/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 2.2620 - val_accuracy: 0.8860\n",
            "Epoch 89/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9887 - val_loss: 2.3269 - val_accuracy: 0.8718\n",
            "Epoch 90/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 2.2478 - val_accuracy: 0.8753\n",
            "Epoch 91/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 2.4399 - val_accuracy: 0.8802\n",
            "Epoch 92/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 2.4305 - val_accuracy: 0.8879\n",
            "Epoch 93/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0288 - accuracy: 0.9929 - val_loss: 2.2439 - val_accuracy: 0.8811\n",
            "Epoch 94/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 2.3370 - val_accuracy: 0.8851\n",
            "Epoch 95/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 2.2556 - val_accuracy: 0.8823\n",
            "Epoch 96/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 2.4737 - val_accuracy: 0.8795\n",
            "Epoch 97/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0491 - accuracy: 0.9906 - val_loss: 2.4081 - val_accuracy: 0.8732\n",
            "Epoch 98/100\n",
            "624/624 [==============================] - 3s 4ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 2.3653 - val_accuracy: 0.8828\n",
            "Epoch 99/100\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 2.3015 - val_accuracy: 0.8816\n",
            "Epoch 100/100\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 2.6299 - val_accuracy: 0.8835\n",
            "134/134 [==============================] - 0s 2ms/step\n",
            "CNN Validation Accuracy: 88.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "db_kO7dnY_yU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}