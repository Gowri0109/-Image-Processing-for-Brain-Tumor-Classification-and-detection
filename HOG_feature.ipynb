{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gowri\\AppData\\Local\\Temp\\ipykernel_16640\\2888927076.py:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features = np.array(features)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m     np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39m\"\u001b[39m\u001b[39mlabels.npy\u001b[39m\u001b[39m\"\u001b[39m), labels)\n\u001b[0;32m     55\u001b[0m \u001b[39m# # Extract HOG features for the training set and save the features in the output directory\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m extract_hog_features(train_dir, output_dir_train)\n\u001b[0;32m     58\u001b[0m \u001b[39m# # Extract HOG features for the validation set and save the features in the output directory\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# extract_hog_features(val_dir, output_dir_val)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[39m# Extract HOG features for the test set and save the features in the output directory\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m# extract_hog_features(test_dir, output_dir_test)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mextract_hog_features\u001b[1;34m(image_dir, output_dir)\u001b[0m\n\u001b[0;32m     49\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(labels)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Save the feature vectors and labels to files\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m np\u001b[39m.\u001b[39;49msave(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(output_dir, \u001b[39m\"\u001b[39;49m\u001b[39mhog_features.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m), features)\n\u001b[0;32m     53\u001b[0m np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39m\"\u001b[39m\u001b[39mlabels.npy\u001b[39m\u001b[39m\"\u001b[39m), labels)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\npyio.py:522\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[0;32m    521\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    523\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\format.py:700\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 700\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(array, fp, protocol\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    701\u001b[0m \u001b[39melif\u001b[39;00m array\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m array\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous:\n\u001b[0;32m    702\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define the paths to the directories for each set\n",
    "train_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\training_set\"\n",
    "# val_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\validation_set\"\n",
    "# test_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\test_set\"\n",
    "\n",
    "# Define the output directories for saving the feature vectors\n",
    "output_dir_train = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\train\"\n",
    "# output_dir_val = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\val\"\n",
    "# output_dir_test = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\test\"\n",
    "\n",
    "# Define the HOG parameters\n",
    "cell_size = (8, 8)\n",
    "block_size = (2, 2)\n",
    "num_bins = 9\n",
    "\n",
    "# Function to extract HOG features from a set of images\n",
    "def extract_hog_features(image_dir, output_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop over each subdirectory (class) in the image directory\n",
    "    for subdir in os.listdir(image_dir):\n",
    "        sub_dir_path = os.path.join(image_dir, subdir)\n",
    "        \n",
    "        # Loop over each image file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, file)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features = hog(gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size)\n",
    "            \n",
    "            # Append the features and label\n",
    "            features.append(hog_features)\n",
    "            labels.append(subdir)\n",
    "    \n",
    "    # Convert the feature and label lists to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Save the feature vectors and labels to files\n",
    "    np.save(os.path.join(output_dir, \"hog_features.npy\"), features)\n",
    "    np.save(os.path.join(output_dir, \"labels.npy\"), labels)\n",
    "\n",
    "# # Extract HOG features for the training set and save the features in the output directory\n",
    "extract_hog_features(train_dir, output_dir_train)\n",
    "\n",
    "# # Extract HOG features for the validation set and save the features in the output directory\n",
    "# extract_hog_features(val_dir, output_dir_val)\n",
    "\n",
    "# Extract HOG features for the test set and save the features in the output directory\n",
    "# extract_hog_features(test_dir, output_dir_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
