{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\master_thesis\\\\datasets\\\\data_split\\\\glioma_tumor\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m split_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tumor_dir, split_folder)\n\u001b[0;32m     24\u001b[0m \u001b[39m# Get the list of image files in the split folder\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m image_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(split_dir)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Initialize empty lists to store the feature vectors and corresponding labels\u001b[39;00m\n\u001b[0;32m     28\u001b[0m features \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\master_thesis\\\\datasets\\\\data_split\\\\glioma_tumor\\\\train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.feature as skif\n",
    "\n",
    "# Define the tumor types\n",
    "tumor_types = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
    "\n",
    "# Define the directory paths for each tumor type and split (train, val, test)\n",
    "data_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\"  # Root directory where the split folders are located\n",
    "\n",
    "# Define the HOG parameters\n",
    "cell_size = (8, 8)\n",
    "block_size = (2, 2)\n",
    "num_bins = 9\n",
    "\n",
    "# Loop over each tumor type\n",
    "for tumor_type in tumor_types:\n",
    "    tumor_dir = os.path.join(data_dir, tumor_type)\n",
    "    \n",
    "    # Loop over each split folder (train, val, test)\n",
    "    for split_folder in [\"train\", \"val\", \"test\"]:\n",
    "        split_dir = os.path.join(tumor_dir, split_folder)\n",
    "        \n",
    "        # Get the list of image files in the split folder\n",
    "        image_files = os.listdir(split_dir)\n",
    "        \n",
    "        # Initialize empty lists to store the feature vectors and corresponding labels\n",
    "        features = []\n",
    "        labels = []\n",
    "        \n",
    "        # Loop over each image file\n",
    "        for image_file in image_files:\n",
    "            # Load the image\n",
    "            image_path = os.path.join(split_dir, image_file)\n",
    "            image = skimage.io.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            image_gray = skimage.color.rgb2gray(image)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features = skif.hog(image_gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size)\n",
    "            \n",
    "            # Append the HOG features and label to the lists\n",
    "            features.append(hog_features)\n",
    "            labels.append(tumor_type)\n",
    "        \n",
    "        # Convert the feature and label lists to numpy arrays\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Save the HOG features and labels to files for the current split folder\n",
    "        features_file = os.path.join(split_dir, \"hog_features.npy\")\n",
    "        labels_file = os.path.join(split_dir, \"labels.npy\")\n",
    "        np.save(features_file, features)\n",
    "        np.save(labels_file, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gowri\\AppData\\Local\\Temp\\ipykernel_2984\\3238416730.py:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features = np.array(features)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define the paths to the directories for each set\n",
    "train_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\training_set\"\n",
    "# val_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\validation_set\"\n",
    "# test_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\test_set\"\n",
    "\n",
    "# Define the output directories for saving the feature vectors\n",
    "output_dir_train = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\train\"\n",
    "# output_dir_val = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\val\"\n",
    "# output_dir_test = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\test\"\n",
    "\n",
    "# Define the HOG parameters\n",
    "cell_size = (8, 8)\n",
    "block_size = (2, 2)\n",
    "num_bins = 9\n",
    "\n",
    "# Function to extract HOG features from a set of images\n",
    "def extract_hog_features(image_dir, output_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop over each subdirectory (class) in the image directory\n",
    "    for subdir in os.listdir(image_dir):\n",
    "        sub_dir_path = os.path.join(image_dir, subdir)\n",
    "        \n",
    "        # Loop over each image file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, file)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features = hog(gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size)\n",
    "            \n",
    "            # Append the features and label\n",
    "            features.append(hog_features)\n",
    "            labels.append(subdir)\n",
    "    \n",
    "    # Convert the feature and label lists to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Save the feature vectors and labels to files\n",
    "    np.save(os.path.join(output_dir, \"hog_features.npy\"), features)\n",
    "    np.save(os.path.join(output_dir, \"labels.npy\"), labels)\n",
    "\n",
    "# # Extract HOG features for the training set and save the features in the output directory\n",
    "extract_hog_features(train_dir, output_dir_train)\n",
    "\n",
    "# # Extract HOG features for the validation set and save the features in the output directory\n",
    "# extract_hog_features(val_dir, output_dir_val)\n",
    "\n",
    "# Extract HOG features for the test set and save the features in the output directory\n",
    "# extract_hog_features(test_dir, output_dir_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define the paths to the directories for each set\n",
    "train_dir = \"path/to/train/\"\n",
    "val_dir = \"path/to/validation/\"\n",
    "test_dir = \"path/to/test/\"\n",
    "\n",
    "# Define the HOG parameters\n",
    "cell_size = (8, 8)\n",
    "block_size = (2, 2)\n",
    "num_bins = 9\n",
    "\n",
    "# Function to extract HOG features from a set of images\n",
    "def extract_hog_features(image_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop over each subdirectory (class) in the image directory\n",
    "    for subdir in os.listdir(image_dir):\n",
    "        sub_dir_path = os.path.join(image_dir, subdir)\n",
    "        \n",
    "        # Loop over each image file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, file)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features = hog(gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size)\n",
    "            \n",
    "            # Append the features and label\n",
    "            features.append(hog_features)\n",
    "            labels.append(subdir)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Extract HOG features for the training set\n",
    "train_features, train_labels = extract_hog_features(train_dir)\n",
    "\n",
    "# Extract HOG features for the validation set\n",
    "val_features, val_labels = extract_hog_features(val_dir)\n",
    "\n",
    "# Extract HOG features for the test set\n",
    "test_features, test_labels = extract_hog_features(test_dir)\n",
    "\n",
    "# Convert the feature and label lists to numpy arrays\n",
    "train_features = np.array(train_features, dtype=object)\n",
    "train_labels = np.array(train_labels)\n",
    "val_features = np.array(val_features, dtype=object)\n",
    "val_labels = np.array(val_labels)\n",
    "test_features = np.array(test_features, dtype=object)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Save the feature vectors and labels to files\n",
    "np.save(\"train_hog_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"val_hog_features.npy\", val_features)\n",
    "np.save(\"val_labels.npy\", val_labels)\n",
    "np.save(\"test_hog_features.npy\", test_features)\n",
    "np.save(\"test_labels.npy\", test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m             cv2\u001b[39m.\u001b[39mimwrite(hog_image_path, hog_image)\n\u001b[0;32m     40\u001b[0m \u001b[39m# Extract and save HOG features for the training set\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m extract_and_save_hog_features(train_dir, \u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmaster_thesis\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdatasets\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mhog_feature\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m \u001b[39m# Extract and save HOG features for the validation set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m extract_and_save_hog_features(val_dir, \u001b[39m\"\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmaster_thesis\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdatasets\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhog_feature\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m, in \u001b[0;36mextract_and_save_hog_features\u001b[1;34m(image_dir, output_dir)\u001b[0m\n\u001b[0;32m     31\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     33\u001b[0m \u001b[39m# Calculate the HOG features\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m hog_features, hog_image \u001b[39m=\u001b[39m hog(gray, orientations\u001b[39m=\u001b[39;49mnum_bins, pixels_per_cell\u001b[39m=\u001b[39;49mcell_size, cells_per_block\u001b[39m=\u001b[39;49mblock_size, visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     36\u001b[0m \u001b[39m# Save the HOG feature visualization as an image\u001b[39;00m\n\u001b[0;32m     37\u001b[0m hog_image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_sub_dir, file)\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\skimage\\_shared\\utils.py:326\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    328\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\skimage\\feature\\_hog.py:287\u001b[0m, in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_blocks_col):\n\u001b[0;32m    286\u001b[0m         block \u001b[39m=\u001b[39m orientation_histogram[r:r \u001b[39m+\u001b[39m b_row, c:c \u001b[39m+\u001b[39m b_col, :]\n\u001b[1;32m--> 287\u001b[0m         normalized_blocks[r, c, :] \u001b[39m=\u001b[39m \\\n\u001b[0;32m    288\u001b[0m             _hog_normalize_block(block, method\u001b[39m=\u001b[39mblock_norm)\n\u001b[0;32m    290\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[39mThe final step collects the HOG descriptors from all blocks of a dense\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39moverlapping grid of blocks covering the detection window into a combined\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mfeature vector for use in the window classifier.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m feature_vector:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define the paths to the directories for each set\n",
    "train_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\training_set\"\n",
    "val_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\validation_set\"\n",
    "test_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\test_set\"\n",
    "\n",
    "# Define the HOG parameters\n",
    "cell_size = (8, 8)\n",
    "block_size = (2, 2)\n",
    "num_bins = 9\n",
    "\n",
    "# Function to extract HOG features from a set of images and save as images\n",
    "def extract_and_save_hog_features(image_dir, output_dir):\n",
    "    # Loop over each subdirectory (class) in the image directory\n",
    "    for subdir in os.listdir(image_dir):\n",
    "        sub_dir_path = os.path.join(image_dir, subdir)\n",
    "        output_sub_dir = os.path.join(output_dir, subdir)\n",
    "        os.makedirs(output_sub_dir, exist_ok=True)\n",
    "        \n",
    "        # Loop over each image file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, file)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features, hog_image = hog(gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size, visualize=True)\n",
    "            \n",
    "            # Save the HOG feature visualization as an image\n",
    "            hog_image_path = os.path.join(output_sub_dir, file)\n",
    "            cv2.imwrite(hog_image_path, hog_image)\n",
    "\n",
    "# Extract and save HOG features for the training set\n",
    "extract_and_save_hog_features(train_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\train\")\n",
    "\n",
    "# Extract and save HOG features for the validation set\n",
    "extract_and_save_hog_features(val_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\val\")\n",
    "\n",
    "# Extract and save HOG features for the test set\n",
    "extract_and_save_hog_features(test_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     43\u001b[0m             cv2\u001b[39m.\u001b[39mimwrite(hog_image_path, hog_image)\n\u001b[0;32m     45\u001b[0m \u001b[39m# Extract and save HOG features for the training set\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m# extract_and_save_hog_features(train_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\train\")\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[39m# Extract and save HOG features for the test set\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m extract_and_save_hog_features(test_dir, \u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmaster_thesis\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdatasets\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mhog_feature\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m, in \u001b[0;36mextract_and_save_hog_features\u001b[1;34m(image_dir, output_dir)\u001b[0m\n\u001b[0;32m     36\u001b[0m normalized \u001b[39m=\u001b[39m exposure\u001b[39m.\u001b[39mrescale_intensity(gray)\n\u001b[0;32m     38\u001b[0m \u001b[39m# Calculate the HOG features\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m hog_features, hog_image \u001b[39m=\u001b[39m hog(normalized, orientations\u001b[39m=\u001b[39;49morientations, pixels_per_cell\u001b[39m=\u001b[39;49mpixels_per_cell, cells_per_block\u001b[39m=\u001b[39;49mcells_per_block, visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     41\u001b[0m \u001b[39m# Save the HOG feature visualization as an image\u001b[39;00m\n\u001b[0;32m     42\u001b[0m hog_image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_sub_dir, file)\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\skimage\\_shared\\utils.py:326\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    328\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32mc:\\Users\\Gowri\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\skimage\\feature\\_hog.py:260\u001b[0m, in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[0m\n\u001b[0;32m    254\u001b[0m                 centre \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([r \u001b[39m*\u001b[39m c_row \u001b[39m+\u001b[39m c_row \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m                                 c \u001b[39m*\u001b[39m c_col \u001b[39m+\u001b[39m c_col \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m])\n\u001b[0;32m    256\u001b[0m                 rr, cc \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39mline(\u001b[39mint\u001b[39m(centre[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m dc),\n\u001b[0;32m    257\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m dr),\n\u001b[0;32m    258\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m dc),\n\u001b[0;32m    259\u001b[0m                                    \u001b[39mint\u001b[39m(centre[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m dr))\n\u001b[1;32m--> 260\u001b[0m                 hog_image[rr, cc] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m orientation_histogram[r, c, o]\n\u001b[0;32m    262\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39mThe fourth stage computes normalization, which takes local groups of\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mcells and contrast normalizes their overall responses before passing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mGradient (HOG) descriptors.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m n_blocks_row \u001b[39m=\u001b[39m (n_cells_row \u001b[39m-\u001b[39m b_row) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Define the paths to the directories for each set\n",
    "# train_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\training_set\"\n",
    "# val_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\validation_set\"\n",
    "test_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\test_set\"\n",
    "\n",
    "\n",
    "# Define the HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "# Function to extract HOG features from a set of images and save as images\n",
    "def extract_and_save_hog_features(image_dir, output_dir):\n",
    "    # Loop over each subdirectory (class) in the image directory\n",
    "    for subdir in os.listdir(image_dir):\n",
    "        sub_dir_path = os.path.join(image_dir, subdir)\n",
    "        output_sub_dir = os.path.join(output_dir, subdir)\n",
    "        os.makedirs(output_sub_dir, exist_ok=True)\n",
    "        \n",
    "        # Loop over each image file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            image_path = os.path.join(sub_dir_path, file)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Normalize the image to enhance contrast\n",
    "            normalized = exposure.rescale_intensity(gray)\n",
    "            \n",
    "            # Calculate the HOG features\n",
    "            hog_features, hog_image = hog(normalized, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)\n",
    "            \n",
    "            # Save the HOG feature visualization as an image\n",
    "            hog_image_path = os.path.join(output_sub_dir, file)\n",
    "            cv2.imwrite(hog_image_path, hog_image)\n",
    "\n",
    "# Extract and save HOG features for the training set\n",
    "# extract_and_save_hog_features(train_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\train\")\n",
    "\n",
    "# # Extract and save HOG features for the validation set\n",
    "# extract_and_save_hog_features(val_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\val\")\n",
    "\n",
    "# Extract and save HOG features for the test set\n",
    "extract_and_save_hog_features(test_dir, \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
