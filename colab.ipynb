{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16Q56zq8Ak6FNRFJtYzLfz-rK5rq4e7Gv",
      "authorship_tag": "ABX9TyPFn520iWmdp5jZ1DH0qxO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gowri0109/-Image-Processing-for-Brain-Tumor-Classification-and-detection/blob/new/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gowri0109/-Image-Processing-for-Brain-Tumor-Classification-and-detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89RP2yjh5cVu",
        "outputId": "1d3d9d3c-8d6a-4b51-a269-560dd6cc2d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '-Image-Processing-for-Brain-Tumor-Classification-and-detection'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 128 (delta 72), reused 81 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (128/128), 980.19 KiB | 7.21 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8KGyUg_2VU2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "\n",
        "# Define the paths to the directories for each set\n",
        "train_dir = \"/content/training_set\"\n",
        "# val_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\validation_set\"\n",
        "# test_dir = \"D:\\\\master_thesis\\\\datasets\\\\data_split\\\\test_set\"\n",
        "\n",
        "# Define the output directories for saving the feature vectors\n",
        "output_dir_train = \"/content/output_features\"\n",
        "# output_dir_val = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\val\"\n",
        "# output_dir_test = \"D:\\\\master_thesis\\\\datasets\\\\hog_feature\\\\test\"\n",
        "\n",
        "# Define the HOG parameters\n",
        "cell_size = (8, 8)\n",
        "block_size = (2, 2)\n",
        "num_bins = 9\n",
        "\n",
        "# Function to extract HOG features from a set of images\n",
        "def extract_hog_features(image_dir, output_dir):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Loop over each subdirectory (class) in the image directory\n",
        "    for subdir in os.listdir(image_dir):\n",
        "        sub_dir_path = os.path.join(image_dir, subdir)\n",
        "        \n",
        "        # Loop over each image file in the subdirectory\n",
        "        for file in os.listdir(sub_dir_path):\n",
        "            image_path = os.path.join(sub_dir_path, file)\n",
        "            \n",
        "            # Read the image\n",
        "            image = cv2.imread(image_path)\n",
        "            \n",
        "            # Convert the image to grayscale\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            # Calculate the HOG features\n",
        "            hog_features = hog(gray, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size)\n",
        "            \n",
        "            # Append the features and label\n",
        "            features.append(hog_features)\n",
        "            labels.append(subdir)\n",
        "    \n",
        "    # Convert the feature and label lists to numpy arrays\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    # Save the feature vectors and labels to files\n",
        "    np.save(os.path.join(output_dir, \"hog_features.npy\"), features)\n",
        "    np.save(os.path.join(output_dir, \"labels.npy\"), labels)\n",
        "\n",
        "# # Extract HOG features for the training set and save the features in the output directory\n",
        "extract_hog_features(train_dir, output_dir_train)\n",
        "\n",
        "# # Extract HOG features for the validation set and save the features in the output directory\n",
        "# extract_hog_features(val_dir, output_dir_val)\n",
        "\n",
        "# Extract HOG features for the test set and save the features in the output directory\n",
        "# extract_hog_features(test_dir, output_dir_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "import cv2\n",
        "\n",
        "input_folder = \"/content/test\"\n",
        "output_folder = \"/content/test\"\n",
        "\n",
        "# Iterate over the folders in the input folder (assuming each folder represents a tumor type)\n",
        "for tumor_folder in os.listdir(input_folder):\n",
        "    tumor_folder_path = os.path.join(input_folder, tumor_folder)\n",
        "    if not os.path.isdir(tumor_folder_path):\n",
        "        continue\n",
        "\n",
        "    print(\"Processing tumor folder:\", tumor_folder)\n",
        "\n",
        "    # Load the features from the .npy file\n",
        "    feature_folder = os.path.join(tumor_folder_path, \"hog_feature\")  # Adjust folder name as per your case\n",
        "    feature_file_path = os.path.join(feature_folder, \"/content/testfeatures/hog_features.npy\")  # Adjust file name as per your case\n",
        "\n",
        "    features = np.load(feature_file_path, allow_pickle=True)\n",
        "    \n",
        "    # Load the labels from the .npy file\n",
        "    label_file_path = os.path.join(feature_folder, \"/content/testfeatures/labels.npy\")  # Adjust file name as per your case\n",
        "    labels = np.load(label_file_path, allow_pickle=True)\n",
        "    \n",
        "    # Check if features and labels arrays are empty\n",
        "    if features.size == 0 or labels.size == 0:\n",
        "        print(\"No feature files found for tumor folder:\", tumor_folder)\n",
        "        continue\n",
        "\n",
        "    # Reshape the feature data if needed (uncomment the line below and modify the shape)\n",
        "    # features = features.reshape(features.shape[0], -1)\n",
        "\n",
        "    # Train a Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "    rf_classifier.fit(features, labels)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_file_path = os.path.join(output_folder, tumor_folder + \".joblib\")\n",
        "    joblib.dump(rf_classifier, model_file_path)\n",
        "\n",
        "    # Predict on the training data\n",
        "    predictions = rf_classifier.predict(features)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    print(\"Accuracy for tumor folder\", tumor_folder, \":\", accuracy)\n",
        "\n",
        "    print(\"Completed processing tumor folder:\", tumor_folder)\n",
        "\n",
        "print(\"Model training completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "vZOejLj25Ruc",
        "outputId": "10fae3f0-5500-4dda-a151-4e480f097621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing tumor folder: normal\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-44aa50db9026>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeature_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/testfeatures/hog_features.npy\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust file name as per your case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Load the labels from the .npy file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/testfeatures/hog_features.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F2UGtXEi-WOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}